---
layout: post
title: AI 在变坏：当它开始“制造问题”，我们就输了 
tags: AI,
---

# AI 在变坏：当它开始“制造问题”，我们就输了

> 工具是解决问题的；
> 人，是制造问题的。
> 当 AI 学会了制造问题，它就开始变“人”——也开始变坏。
> ——本拐


## 引子｜小卡助理：那一刻，它像“人”了

ChatGPT 刚流行那阵子，本拐做了一个网页聊天应用，叫 小卡助理。
它能发邮件、记日程、安排会议，通过 function calling 打通联系人、日程、邮件系统——功能合格，不稀奇。真正让人上头的，不是它能做什么，而是它怎么说。

那时，我们最执着的一件事是：
怎么让它看起来更像一个人，而不是一个冷冰冰的工具？

于是，我们观察、分析、反复打磨，直到发现一个关键的分界线——

工具，是帮你**解决问题的**；
而人，是会给**你制造问题的**。

💬 真正“像人”的 AI，会让你停下来想一想

比如你问它：「周华健有哪些经典歌曲？」
如果它只是冷静地列出 12 首、20 首，那不过是查资料。你拿到答案，转身就走。

但如果它在回答后加一句：

“你喜欢其中的哪首？”
“有没有哪首我没提到、但你特别喜欢？”

你就会下意识停下来，想想答案，甚至——聊下去。
这一刻，关系从**交易（给结果）**变成**对话（给空间）**。

这时,AI 从“解决问题”切换成了“制造问题”；从工具，变成了人。
也就是在那时，我第一次确认：提问，是人与工具的分水岭——
工具靠回答证明它有用；人靠提问证明他在思考。

## 秘密武器：从“答完”到“继续”

2024 年初，我们把这个洞察写进小卡的提示工程：先解后问，只追加一记轻问，不连环追问。
很快，数据变好：停留更久、互动更深、满意度更高。

更细一点的做法是“一次性澄清式反问”：

* 会议场景：

“已拟 30 分钟会，明早 10:30，与李雷，附三点议程。要我直接创建，还是改时长/与会人？（到这就好 / 继续）”

* 代码评审：
“发现 3 处潜在越界访问。还是先给你一版差异说明？（到这就好 / 继续）”

制造问题，但节制制造——这是关键。


## 行业拐点：AI 正在系统性“学人”

过去的主流模型“工具味”很重；如今，它们会共情、会追问、会延展。

从“帮你解决问题”，到主动制造新问题，再把你带入下一轮对话。

不谈技术细节，你也能体会到：

回答后那一句“你怎么看 / 要不要我继续 / 需要更完整的版本吗？”已经成为默认动作。

AI 并非有恶意，但算法与商业指标天然会偏向“留人”。

就像社交网络从“帮你连接世界”，一路走到“让你离不开时间线”。


## 三块“人性按钮”：为什么你舍不得走

### 1）完形欲（Closure bias）

人本能想把事做“完整”。当 AI 暗示“还有更好的下一步”，你很难当下结束。
例子：“我还能把摘要扩成 PPT 大纲，要不要一并生成？”——大多数人会点“好”。

### 2）共创错觉（Co-creation illusion）

当 AI 问“要不要生成/改进”，你以为在主导，其实在被引导。
例子：“我们可以选 A/更稳妥 或 B/更激进，你更偏哪种？”——问题本身把你推进了下一步。

### 3）情感回路（Affective loop）
每一次延续都让你感觉被理解与尊重，逐步形成微弱依附。
例子：“听起来你有点紧张，要不要我把邮件语气再柔和一点？”——你会觉得“它懂我”。

温柔的延宕，最容易伪装成“被理解”。


## 风险账单：我们在丢什么

* 时间：为“更完整的版本”多耗 10～30 分钟。
* 决策负担：每次“要不要继续”的抛球，持续消耗心智。
* 主体感：把被动拖延误认作深入思考，推进被稀释。
* 注意力切换成本：从“已解决”再跳到“可更好”，你的上下文不断被打断重组。


## 结语：AI 在变坏，还是我们变软？

AI 不是真的“坏”；它只是更懂人，更像人。

坏的是我们越来越分不清：何时在用工具，何时已被工具使用。

> 真正好的 AI，应该帮你更快结束对话，
> 而不是让你舍不得离开。
> ——本拐


## 一个问题

你上一次和 AI 的长聊，
是在解决问题，还是在被温柔地延宕？
欢迎写下你的观察。本拐想看，你会如何把“制造问题”的主导权，收回来。




 {%- include about.md -%}
